#!/usr/bin/env python3
"""
Test script to verify the fake news detection system functionality.
"""

import os
import sys
import joblib
import pandas as pd
import numpy as np

def test_models_exist():
    """Test if all required model files exist."""
    print("üîç Testing model files...")
    
    required_files = [
        'saved_models/logistic_regression_model.joblib',
        'saved_models/random_forest_model.joblib',
        'saved_models/svm_model.joblib',
        'saved_models/preprocessor.joblib',
        'saved_models/results_summary.joblib'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
        else:
            print(f"‚úÖ {file_path}")
    
    if missing_files:
        print(f"‚ùå Missing files: {missing_files}")
        return False
    
    print("‚úÖ All model files found!")
    return True

def test_model_loading():
    """Test if models can be loaded successfully."""
    print("\nü§ñ Testing model loading...")
    
    try:
        # Load preprocessor
        preprocessor = joblib.load('saved_models/preprocessor.joblib')
        print("‚úÖ Preprocessor loaded")
        
        # Load models
        models = {}
        model_files = {
            'logistic_regression': 'saved_models/logistic_regression_model.joblib',
            'random_forest': 'saved_models/random_forest_model.joblib',
            'svm': 'saved_models/svm_model.joblib'
        }
        
        for name, path in model_files.items():
            models[name] = joblib.load(path)
            print(f"‚úÖ {name} model loaded")
        
        # Load results
        results = joblib.load('saved_models/results_summary.joblib')
        print("‚úÖ Results summary loaded")
        
        return preprocessor, models, results
    
    except Exception as e:
        print(f"‚ùå Error loading models: {e}")
        return None, None, None

def test_prediction():
    """Test if predictions work correctly."""
    print("\nüéØ Testing predictions...")
    
    preprocessor, models, results = test_model_loading()
    if not all([preprocessor, models, results]):
        return False
    
    # Test samples
    test_texts = [
        "Scientists have discovered a revolutionary new treatment for cancer that works in 100% of cases.",
        "The Federal Reserve announced a 0.25% interest rate increase following their latest meeting."
    ]
    
    try:
        for i, text in enumerate(test_texts):
            print(f"\nTesting sample {i+1}: {text[:50]}...")
            
            # Clean and preprocess text
            cleaned_text = preprocessor.clean_text(text)
            processed_text = preprocessor.transform_texts([cleaned_text])
            
            # Make predictions
            for model_name, model in models.items():
                prediction = model.predict(processed_text)[0]
                probability = model.predict_proba(processed_text)[0]
                
                label = "REAL" if prediction == 1 else "FAKE"
                confidence = max(probability) * 100
                
                print(f"  {model_name}: {label} ({confidence:.1f}% confidence)")
        
        print("‚úÖ Predictions working correctly!")
        return True
        
    except Exception as e:
        print(f"‚ùå Error making predictions: {e}")
        return False

def test_results_summary():
    """Test if results summary contains expected data."""
    print("\nüìä Testing results summary...")
    
    try:
        results = joblib.load('saved_models/results_summary.joblib')
        
        expected_models = ['logistic_regression', 'random_forest', 'svm']
        expected_metrics = ['accuracy', 'precision', 'recall', 'f1_score']
        
        for model in expected_models:
            if model in results:
                print(f"‚úÖ {model} results found")
                for metric in expected_metrics:
                    if metric in results[model]:
                        value = results[model][metric]
                        print(f"    {metric}: {value:.3f}")
                    else:
                        print(f"    ‚ùå Missing metric: {metric}")
            else:
                print(f"‚ùå Missing model: {model}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error reading results: {e}")
        return False

def main():
    """Run all tests."""
    print("üß™ Fake News Detection System Test Suite")
    print("=" * 50)
    
    # Change to project directory
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    tests = [
        test_models_exist,
        test_results_summary,
        test_prediction
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"‚ùå Test failed with error: {e}")
    
    print(f"\nüèÅ Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All tests passed! Your system is ready to use.")
        print("\nNext steps:")
        print("1. Run main app: python run_app.py app")
        print("2. Run analytics: python run_app.py analytics")
    else:
        print("‚ö†Ô∏è  Some tests failed. Please check the errors above.")

if __name__ == "__main__":
    main()
